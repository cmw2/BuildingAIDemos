{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "879f6efa",
   "metadata": {},
   "source": [
    "# Sample 02: OpenAI SDK with Python (Jupyter Notebook)\n",
    "\n",
    "This notebook demonstrates how to use the OpenAI Python SDK to connect to AI Foundry models. We'll explore basic chat completions, streaming responses, and different configuration options.\n",
    "\n",
    "## Prerequisites\n",
    "- Python environment with required packages installed\n",
    "- `.env` file configured with AI Foundry credentials\n",
    "- OpenAI Python SDK installed\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cc135f",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Configuration\n",
    "\n",
    "First, let's verify our environment and install any missing packages. The required packages should already be installed if you followed the main README setup instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7731180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify required packages are installed\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def check_package(package_name):\n",
    "    try:\n",
    "        __import__(package_name)\n",
    "        print(f\"‚úÖ {package_name} is installed\")\n",
    "        return True\n",
    "    except ImportError:\n",
    "        print(f\"‚ùå {package_name} is not installed\")\n",
    "        return False\n",
    "\n",
    "# Check required packages\n",
    "packages = ['openai', 'dotenv']\n",
    "all_installed = all(check_package(pkg) for pkg in packages)\n",
    "\n",
    "if all_installed:\n",
    "    print(\"\\nüéâ All required packages are installed!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Some packages are missing. Please run: pip install -r requirements.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba02748",
   "metadata": {},
   "source": [
    "## 2. Import Required Libraries\n",
    "\n",
    "Now let's import all the libraries we'll need for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9ac987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "import time\n",
    "\n",
    "print(\"üì¶ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af19e580",
   "metadata": {},
   "source": [
    "## 3. Load Environment Variables\n",
    "\n",
    "Load our AI Foundry configuration from the `.env` file. Make sure you've copied `.env.example` to `.env` and filled in your actual credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed8978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "# Note: The .env file should be in the root directory (../../.env from this notebook)\n",
    "load_dotenv('../../.env')\n",
    "\n",
    "# Get configuration from environment variables\n",
    "azure_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "deployment_name = os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME')\n",
    "api_version = os.getenv('AZURE_OPENAI_API_VERSION')\n",
    "\n",
    "# Verify configuration is loaded\n",
    "print(\"üîß Configuration Status:\")\n",
    "print(f\"Endpoint: {'‚úÖ Loaded' if azure_endpoint else '‚ùå Missing'}\")\n",
    "print(f\"Deployment: {'‚úÖ Loaded' if deployment_name else '‚ùå Missing'}\")\n",
    "print(f\"API Version: {'‚úÖ Loaded' if api_version else '‚ùå Missing'}\")\n",
    "\n",
    "if all([azure_endpoint, deployment_name, api_version]):\n",
    "    print(\"\\nüéâ All configuration loaded successfully!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Some configuration is missing. Please check your .env file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5858856",
   "metadata": {},
   "source": [
    "## 4. Initialize OpenAI Client\n",
    "\n",
    "Create the Azure OpenAI client using our configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43acc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Azure OpenAI client with DefaultAzureCredential\n",
    "token_provider = get_bearer_token_provider(\n",
    "    DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\"\n",
    ")\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    azure_ad_token_provider=token_provider,\n",
    "    api_version=api_version\n",
    ")\n",
    "\n",
    "print(\"üöÄ Azure OpenAI client initialized successfully with DefaultAzureCredential!\")\n",
    "print(f\"Connected to: {azure_endpoint}\")\n",
    "print(f\"Using deployment: {deployment_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492a5aba",
   "metadata": {},
   "source": [
    "## 5. Basic Chat Completion\n",
    "\n",
    "Let's start with a simple chat completion request. This is the most basic way to interact with the AI model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d58649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple chat completion example\n",
    "\n",
    "def basic_chat_completion(user_message):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ],\n",
    "            max_tokens=150,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Test the function\n",
    "user_input = \"Hello! Can you tell me a short joke?\"\n",
    "print(\"üë§ User:\", user_input)\n",
    "print(\"ü§ñ AI:\", basic_chat_completion(user_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2224dd72",
   "metadata": {},
   "source": [
    "## 6. Conversation with History\n",
    "\n",
    "Now let's demonstrate how to maintain conversation context by including message history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7838b024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversation with history example\n",
    "def chat_with_history(messages):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=messages,\n",
    "            max_tokens=150,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Create a conversation with history\n",
    "conversation = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the capital of France?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The capital of France is Paris.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the population of that city?\"}\n",
    "]\n",
    "\n",
    "print(\"üìö Conversation History:\")\n",
    "for i, message in enumerate(conversation[1:], 1):  # Skip system message for display\n",
    "    role_emoji = \"üë§\" if message[\"role\"] == \"user\" else \"ü§ñ\"\n",
    "    print(f\"{role_emoji} {message['role'].title()}: {message['content']}\")\n",
    "\n",
    "# Get response with context\n",
    "print(\"\\nü§ñ AI:\", chat_with_history(conversation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa11e78a",
   "metadata": {},
   "source": [
    "## 7. Temperature Variations\n",
    "\n",
    "Temperature controls the randomness of the AI's responses. Let's compare different temperature settings with the same prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b459607f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature comparison\n",
    "def chat_with_temperature(user_message, temperature):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful AI assistant. Keep your response to one sentence.\"},\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ],\n",
    "            max_tokens=100,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Test the same prompt with different temperatures, running each twice\n",
    "# The prompt is open enough for variety at high temp, but focused enough for consistency at low temp\n",
    "prompt = \"Suggest a creative name for a coffee shop.\"\n",
    "temperatures = [\n",
    "    (0.1, \"Low temperature (more consistent)\"),\n",
    "    (1.0, \"High temperature (more varied)\")\n",
    "]\n",
    "\n",
    "print(\"üë§ User:\", prompt)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "for temp, description in temperatures:\n",
    "    print(f\"\\nüå°Ô∏è Temperature {temp} - {description}\")\n",
    "    for run in range(1, 3):\n",
    "        print(f\"\\n  Run {run}:\")\n",
    "        print(f\"  ü§ñ AI:\", chat_with_temperature(prompt, temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2220d0c8",
   "metadata": {},
   "source": [
    "## 8. Interactive Playground\n",
    "\n",
    "Use this cell to experiment with your own prompts and settings. Modify the variables below and run the cell to test different configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648d39c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive playground - modify these variables and run the cell\n",
    "YOUR_SYSTEM_MESSAGE = \"You are a helpful AI assistant.\"\n",
    "YOUR_USER_MESSAGE = \"Tell me an interesting fact about space.\"\n",
    "YOUR_TEMPERATURE = 0.7\n",
    "YOUR_MAX_TOKENS = 150\n",
    "\n",
    "# Run your custom chat completion\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=deployment_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": YOUR_SYSTEM_MESSAGE},\n",
    "            {\"role\": \"user\", \"content\": YOUR_USER_MESSAGE}\n",
    "        ],\n",
    "        max_tokens=YOUR_MAX_TOKENS,\n",
    "        temperature=YOUR_TEMPERATURE\n",
    "    )\n",
    "    \n",
    "    print(\"üéÆ Your Custom Chat:\")\n",
    "    print(f\"üë§ User: {YOUR_USER_MESSAGE}\")\n",
    "    print(f\"ü§ñ AI: {response.choices[0].message.content}\")\n",
    "    print(f\"\\nüìä Settings: Temperature={YOUR_TEMPERATURE}, Max Tokens={YOUR_MAX_TOKENS}\")\n",
    "    print(f\"üìà Usage: {response.usage.total_tokens} tokens used\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a02c8c4",
   "metadata": {},
   "source": [
    "## 9. Summary and Next Steps\n",
    "\n",
    "üéâ **Congratulations!** You've successfully learned how to:\n",
    "\n",
    "1. ‚úÖ Set up the OpenAI Python SDK with Azure OpenAI\n",
    "2. ‚úÖ Load configuration from environment variables\n",
    "3. ‚úÖ Make basic chat completion requests\n",
    "4. ‚úÖ Handle conversation history and context\n",
    "5. ‚úÖ Experiment with temperature settings\n",
    "6. ‚úÖ Create your own interactive playground\n",
    "\n",
    "### Key Takeaways:\n",
    "- **Environment Variables**: Keep your credentials secure by using `.env` files\n",
    "- **Temperature**: Low (0.1) for factual, high (0.9) for creative responses\n",
    "- **Context**: Include message history to maintain conversation flow\n",
    "- **Error Handling**: Always wrap API calls in try-catch blocks\n",
    "\n",
    "### Next Steps:\n",
    "- Explore the other samples in this repository\n",
    "- Try different system messages and prompts\n",
    "- Experiment with other OpenAI parameters like `top_p`, `frequency_penalty`, etc.\n",
    "- Build your own applications using these patterns\n",
    "\n",
    "Happy coding! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
