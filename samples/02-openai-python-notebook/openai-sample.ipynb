{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "879f6efa",
   "metadata": {},
   "source": [
    "# Sample 02: OpenAI SDK with Python (Jupyter Notebook)\n",
    "\n",
    "This notebook demonstrates how to use the OpenAI Python SDK to connect to AI Foundry models. We'll explore basic chat completions, streaming responses, and different configuration options.\n",
    "\n",
    "## Prerequisites\n",
    "- Python environment with required packages installed\n",
    "- `.env` file configured with AI Foundry credentials\n",
    "- OpenAI Python SDK installed\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cc135f",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Configuration\n",
    "\n",
    "First, let's verify our environment and install any missing packages. The required packages should already be installed if you followed the main README setup instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7731180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… openai is installed\n",
      "âœ… dotenv is installed\n",
      "\n",
      "ğŸ‰ All required packages are installed!\n"
     ]
    }
   ],
   "source": [
    "# Verify required packages are installed\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def check_package(package_name):\n",
    "    try:\n",
    "        __import__(package_name)\n",
    "        print(f\"âœ… {package_name} is installed\")\n",
    "        return True\n",
    "    except ImportError:\n",
    "        print(f\"âŒ {package_name} is not installed\")\n",
    "        return False\n",
    "\n",
    "# Check required packages\n",
    "packages = ['openai', 'dotenv']\n",
    "all_installed = all(check_package(pkg) for pkg in packages)\n",
    "\n",
    "if all_installed:\n",
    "    print(\"\\nğŸ‰ All required packages are installed!\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  Some packages are missing. Please run: pip install -r requirements.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba02748",
   "metadata": {},
   "source": [
    "## 2. Import Required Libraries\n",
    "\n",
    "Now let's import all the libraries we'll need for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc9ac987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "import time\n",
    "\n",
    "print(\"ğŸ“¦ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af19e580",
   "metadata": {},
   "source": [
    "## 3. Load Environment Variables\n",
    "\n",
    "Load our AI Foundry configuration from the `.env` file. Make sure you've copied `.env.example` to `.env` and filled in your actual credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ed8978d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Configuration Status:\n",
      "Endpoint: âœ… Loaded\n",
      "API Key: âœ… Loaded\n",
      "Deployment: âœ… Loaded\n",
      "API Version: âœ… Loaded\n",
      "\n",
      "ğŸ‰ All configuration loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "# Note: The .env file should be in the root directory (../../.env from this notebook)\n",
    "load_dotenv('../../.env')\n",
    "\n",
    "# Get configuration from environment variables\n",
    "azure_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "api_key = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "deployment_name = os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME')\n",
    "api_version = os.getenv('AZURE_OPENAI_API_VERSION')\n",
    "\n",
    "# Verify configuration is loaded\n",
    "print(\"ğŸ”§ Configuration Status:\")\n",
    "print(f\"Endpoint: {'âœ… Loaded' if azure_endpoint else 'âŒ Missing'}\")\n",
    "print(f\"API Key: {'âœ… Loaded' if api_key else 'âŒ Missing'}\")\n",
    "print(f\"Deployment: {'âœ… Loaded' if deployment_name else 'âŒ Missing'}\")\n",
    "print(f\"API Version: {'âœ… Loaded' if api_version else 'âŒ Missing'}\")\n",
    "\n",
    "if all([azure_endpoint, api_key, deployment_name, api_version]):\n",
    "    print(\"\\nğŸ‰ All configuration loaded successfully!\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  Some configuration is missing. Please check your .env file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5858856",
   "metadata": {},
   "source": [
    "## 4. Initialize OpenAI Client\n",
    "\n",
    "Create the Azure OpenAI client using our configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e43acc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Azure OpenAI client initialized successfully!\n",
      "Connected to: https://chwestbr-foundry-projec-resource.openai.azure.com/\n",
      "Using deployment: gpt-4o\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Azure OpenAI client\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_key=api_key,\n",
    "    api_version=api_version\n",
    ")\n",
    "\n",
    "print(\"ğŸš€ Azure OpenAI client initialized successfully!\")\n",
    "print(f\"Connected to: {azure_endpoint}\")\n",
    "print(f\"Using deployment: {deployment_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492a5aba",
   "metadata": {},
   "source": [
    "## 5. Basic Chat Completion\n",
    "\n",
    "Let's start with a simple chat completion request. This is the most basic way to interact with the AI model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d58649c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‘¤ User: Hello! Can you tell me a short joke?\n",
      "ğŸ¤– AI: Of course! Here's one for you:\n",
      "\n",
      "Why donâ€™t skeletons fight each other?\n",
      "\n",
      "Because they donâ€™t have the guts! ğŸ˜„\n"
     ]
    }
   ],
   "source": [
    "# Simple chat completion example\n",
    "\n",
    "def basic_chat_completion(user_message):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ],\n",
    "            max_tokens=150,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Test the function\n",
    "user_input = \"Hello! Can you tell me a short joke?\"\n",
    "print(\"ğŸ‘¤ User:\", user_input)\n",
    "print(\"ğŸ¤– AI:\", basic_chat_completion(user_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2224dd72",
   "metadata": {},
   "source": [
    "## 6. Conversation with History\n",
    "\n",
    "Now let's demonstrate how to maintain conversation context by including message history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7838b024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“š Conversation History:\n",
      "ğŸ‘¤ User: What is the capital of France?\n",
      "ğŸ¤– Assistant: The capital of France is Paris.\n",
      "ğŸ‘¤ User: What is the population of that city?\n",
      "\n",
      "ğŸ¤– AI: As of 2023, the population of Paris is approximately **11 million people** in the metropolitan area and around **2.1 million people** within the city limits. The metropolitan area, known as the **Ãle-de-France region**, is one of the most populous urban areas in Europe. Population figures can vary slightly depending on the source and the year of estimation.\n"
     ]
    }
   ],
   "source": [
    "# Conversation with history example\n",
    "def chat_with_history(messages):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=messages,\n",
    "            max_tokens=150,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Create a conversation with history\n",
    "conversation = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the capital of France?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The capital of France is Paris.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the population of that city?\"}\n",
    "]\n",
    "\n",
    "print(\"ğŸ“š Conversation History:\")\n",
    "for i, message in enumerate(conversation[1:], 1):  # Skip system message for display\n",
    "    role_emoji = \"ğŸ‘¤\" if message[\"role\"] == \"user\" else \"ğŸ¤–\"\n",
    "    print(f\"{role_emoji} {message['role'].title()}: {message['content']}\")\n",
    "\n",
    "# Get response with context\n",
    "print(\"\\nğŸ¤– AI:\", chat_with_history(conversation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa11e78a",
   "metadata": {},
   "source": [
    "## 7. Temperature Variations\n",
    "\n",
    "Temperature controls the randomness of the AI's responses. Let's compare different temperature settings with the same prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b459607f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‘¤ User: Explain photosynthesis in simple terms.\n",
      "\n",
      "==================================================\n",
      "\n",
      "ğŸŒ¡ï¸ Temperature 0.1 - Low temperature (factual, consistent)\n",
      "ğŸ¤– AI: Sure! Photosynthesis is the process plants use to make their own food. Here's how it works in simple terms:\n",
      "\n",
      "1. **Plants take in sunlight** using a green substance in their leaves called chlorophyll.\n",
      "2. **They absorb carbon dioxide** from the air through tiny holes in their leaves.\n",
      "3. **They take up water** from the soil through their roots.\n",
      "4. Using the sunlight's energy, plants combine the carbon dioxide and water to make **sugar (food)** and **\n",
      "\n",
      "ğŸŒ¡ï¸ Temperature 0.7 - Medium temperature (balanced)\n",
      "ğŸ¤– AI: Sure! Photosynthesis is the process plants use to make their own food. Here's a simple way to think about it:\n",
      "\n",
      "1. **What plants need:**\n",
      "   - Sunlight (energy from the sun)\n",
      "   - Carbon dioxide (a gas from the air)\n",
      "   - Water (from the soil)\n",
      "\n",
      "2. **What happens:**\n",
      "   - Plants take in sunlight through their leaves and use it as energy.\n",
      "   - They absorb carbon dioxide from the air through tiny holes in their leaves.\n",
      "  \n",
      "\n",
      "ğŸŒ¡ï¸ Temperature 1.0 - High temperature (creative, varied)\n",
      "ğŸ¤– AI: Sure! Photosynthesis is the way plants make their own food. Plants use sunlight, water, and a gas called carbon dioxide (from the air) to make sugar (food) and oxygen.\n",
      "\n",
      "Hereâ€™s how it works, step by step:\n",
      "\n",
      "1. **Sunlight**: Plants soak up sunlight with a special green substance in their leaves called chlorophyll.\n",
      "2. **Water**: Plants take in water through their roots from the soil.\n",
      "3. **Carbon Dioxide**: Plants absorb carbon\n"
     ]
    }
   ],
   "source": [
    "# Temperature comparison\n",
    "def chat_with_temperature(user_message, temperature, description):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ],\n",
    "            max_tokens=100,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Test the same prompt with different temperatures\n",
    "prompt = \"Explain photosynthesis in simple terms.\"\n",
    "temperatures = [\n",
    "    (0.1, \"Low temperature (factual, consistent)\"),\n",
    "    (0.7, \"Medium temperature (balanced)\"),\n",
    "    (1.0, \"High temperature (creative, varied)\")\n",
    "]\n",
    "\n",
    "print(\"ğŸ‘¤ User:\", prompt)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "for temp, description in temperatures:\n",
    "    print(f\"\\nğŸŒ¡ï¸ Temperature {temp} - {description}\")\n",
    "    print(\"ğŸ¤– AI:\", chat_with_temperature(prompt, temp, description))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2220d0c8",
   "metadata": {},
   "source": [
    "## 8. Interactive Playground\n",
    "\n",
    "Use this cell to experiment with your own prompts and settings. Modify the variables below and run the cell to test different configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "648d39c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ® Your Custom Chat:\n",
      "ğŸ‘¤ User: Tell me an interesting fact about space.\n",
      "ğŸ¤– AI: Sure! Did you know that in space, thereâ€™s something called a \"rogue planet\"? These are planets that donâ€™t orbit a star like Earth orbits the Sun. Instead, they wander through the galaxy all alone, drifting in the darkness. Scientists estimate there could be billions of these lonely planets in the Milky Way, and some might even have their own moons or atmospheres!\n",
      "\n",
      "ğŸ“Š Settings: Temperature=0.7, Max Tokens=150\n",
      "ğŸ“ˆ Usage: 105 tokens used\n"
     ]
    }
   ],
   "source": [
    "# Interactive playground - modify these variables and run the cell\n",
    "YOUR_SYSTEM_MESSAGE = \"You are a helpful AI assistant.\"\n",
    "YOUR_USER_MESSAGE = \"Tell me an interesting fact about space.\"\n",
    "YOUR_TEMPERATURE = 0.7\n",
    "YOUR_MAX_TOKENS = 150\n",
    "\n",
    "# Run your custom chat completion\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=deployment_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": YOUR_SYSTEM_MESSAGE},\n",
    "            {\"role\": \"user\", \"content\": YOUR_USER_MESSAGE}\n",
    "        ],\n",
    "        max_tokens=YOUR_MAX_TOKENS,\n",
    "        temperature=YOUR_TEMPERATURE\n",
    "    )\n",
    "    \n",
    "    print(\"ğŸ® Your Custom Chat:\")\n",
    "    print(f\"ğŸ‘¤ User: {YOUR_USER_MESSAGE}\")\n",
    "    print(f\"ğŸ¤– AI: {response.choices[0].message.content}\")\n",
    "    print(f\"\\nğŸ“Š Settings: Temperature={YOUR_TEMPERATURE}, Max Tokens={YOUR_MAX_TOKENS}\")\n",
    "    print(f\"ğŸ“ˆ Usage: {response.usage.total_tokens} tokens used\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a02c8c4",
   "metadata": {},
   "source": [
    "## 9. Summary and Next Steps\n",
    "\n",
    "ğŸ‰ **Congratulations!** You've successfully learned how to:\n",
    "\n",
    "1. âœ… Set up the OpenAI Python SDK with Azure OpenAI\n",
    "2. âœ… Load configuration from environment variables\n",
    "3. âœ… Make basic chat completion requests\n",
    "4. âœ… Handle conversation history and context\n",
    "5. âœ… Experiment with temperature settings\n",
    "6. âœ… Create your own interactive playground\n",
    "\n",
    "### Key Takeaways:\n",
    "- **Environment Variables**: Keep your credentials secure by using `.env` files\n",
    "- **Temperature**: Low (0.1) for factual, high (0.9) for creative responses\n",
    "- **Context**: Include message history to maintain conversation flow\n",
    "- **Error Handling**: Always wrap API calls in try-catch blocks\n",
    "\n",
    "### Next Steps:\n",
    "- Explore the other samples in this repository\n",
    "- Try different system messages and prompts\n",
    "- Experiment with other OpenAI parameters like `top_p`, `frequency_penalty`, etc.\n",
    "- Build your own applications using these patterns\n",
    "\n",
    "Happy coding! ğŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
